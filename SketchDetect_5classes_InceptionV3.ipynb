{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0059b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d97b66",
   "metadata": {},
   "source": [
    "labels = ['rugby', 'soccer']\n",
    "img_size = 224\n",
    "def get_data(data_dir):\n",
    "    data = [] \n",
    "    for label in labels: \n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d064cd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345\n"
     ]
    }
   ],
   "source": [
    "orig_path = 'E:\\SketchClassifier\\quickdraw'\n",
    "print(len(next(os.walk(orig_path))[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97c4d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(orig_path)\n",
    "labels_int = list(range(len(labels)))\n",
    "#print(labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eee4b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []  #input images\n",
    "y_data = []  #output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "428e4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    k = 0\n",
    "    for file in os.listdir(os.path.join(orig_path,str(labels[i]))):\n",
    "        k = k +1\n",
    "        #print(k, labels[i])\n",
    "        image = cv2.imread(str(os.path.join(orig_path,str(labels[i]),file)))\n",
    "        image = cv2.resize(image, (100,100))\n",
    "        x_data.append(image)\n",
    "        y_data.append(labels_int[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1f7a7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(x_data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7dcb6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(100, 100, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_data[0])\n",
    "print(y_data[0])\n",
    "print(x_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad9b661",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "511b65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(np.array(x_data), np.array(y_data), test_size = 0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc0da970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 100, 100, 3), (500, 100, 100, 3)\n",
      "(2000,), (500,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape, sep=', ')\n",
    "print(y_train.shape, y_test.shape, sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25aa96eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d710fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat = to_categorical(y_test, 5)\n",
    "y_train_cat = to_categorical(y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75f3ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise data\n",
    "x_train = x_train/x_train.max()\n",
    "x_test = x_test/x_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91a2e8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,851,784\n",
      "Trainable params: 23,817,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#import model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "\n",
    "inception_orig = InceptionV3(weights='imagenet')\n",
    "\n",
    "inception_orig.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b825c1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 49, 49, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 49, 49, 32)   96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 49, 49, 32)   0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 47, 47, 32)   9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 47, 47, 32)   96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 47, 47, 32)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 47, 47, 64)   18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 47, 47, 64)   192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 47, 47, 64)   0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 23, 23, 64)   0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 23, 23, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 23, 23, 80)   240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 23, 23, 80)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 21, 21, 192)  138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 21, 21, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 21, 21, 192)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 10, 192)  0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 10, 10, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 10, 10, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 10, 10, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 10, 10, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 10, 10, 96)   55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 10, 10, 48)   144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 10, 10, 96)   288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 10, 10, 48)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 10, 10, 96)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 10, 10, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 10, 10, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 10, 10, 64)   76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 10, 10, 96)   82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 10, 10, 32)   6144        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 10, 10, 64)   192         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 10, 10, 64)   192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 10, 10, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 10, 10, 32)   96          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 10, 10, 64)   0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 10, 10, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 10, 10, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 10, 10, 32)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 10, 10, 256)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 10, 10, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 10, 10, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 10, 10, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 10, 10, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 10, 10, 96)   55296       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 10, 10, 48)   144         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 10, 10, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 10, 10, 48)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 10, 10, 96)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 10, 10, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 10, 10, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 10, 10, 64)   76800       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 10, 10, 96)   82944       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 10, 10, 64)   16384       average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 10, 10, 64)   192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 10, 10, 64)   192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 10, 10, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 10, 10, 64)   192         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 10, 10, 64)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 10, 10, 64)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 10, 10, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 10, 10, 64)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 10, 10, 288)  0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 10, 10, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 10, 10, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 10, 10, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 10, 10, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 10, 10, 96)   55296       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 10, 10, 48)   144         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 10, 10, 96)   288         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 10, 10, 48)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 10, 10, 96)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 10, 10, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 10, 10, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 10, 10, 64)   76800       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 10, 10, 96)   82944       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 10, 10, 64)   18432       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 10, 10, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 10, 10, 64)   192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 10, 10, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 10, 10, 64)   192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 10, 10, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 10, 10, 64)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 10, 10, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 10, 10, 64)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 10, 10, 288)  0           activation_113[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 10, 10, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 10, 10, 64)   192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 10, 10, 64)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 10, 10, 96)   55296       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 10, 10, 96)   288         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 10, 10, 96)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 4, 4, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 4, 4, 96)     82944       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 4, 4, 384)    1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 4, 4, 96)     288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 4, 4, 384)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 4, 4, 96)     0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 4, 4, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 4, 4, 768)    0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 4, 4, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 4, 4, 128)    384         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 4, 4, 128)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 4, 4, 128)    114688      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 4, 4, 128)    384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 4, 4, 128)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 4, 4, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 4, 4, 128)    114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 4, 4, 128)    384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 4, 4, 128)    384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 4, 4, 128)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 4, 4, 128)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 4, 4, 128)    114688      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 4, 4, 128)    114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 4, 4, 128)    384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 4, 4, 128)    384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 4, 4, 128)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 4, 4, 128)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 4, 4, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 4, 4, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 4, 4, 192)    172032      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 4, 4, 192)    172032      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 4, 4, 192)    147456      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 4, 4, 192)    576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 4, 4, 192)    576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 4, 4, 192)    576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 4, 4, 192)    576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 4, 4, 192)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 4, 4, 192)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 4, 4, 192)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 4, 4, 192)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 4, 4, 768)    0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 4, 4, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 4, 4, 160)    480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 4, 4, 160)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 4, 4, 160)    179200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 4, 4, 160)    480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 4, 4, 160)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 4, 4, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 4, 4, 160)    179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 4, 4, 160)    480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 4, 4, 160)    480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 4, 4, 160)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 4, 4, 160)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 4, 4, 160)    179200      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 4, 4, 160)    179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 4, 4, 160)    480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 4, 4, 160)    480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 4, 4, 160)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 4, 4, 160)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 4, 4, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 4, 4, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 4, 4, 192)    215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 4, 4, 192)    215040      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 4, 4, 192)    147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 4, 4, 192)    576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 4, 4, 192)    576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 4, 4, 192)    576         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 4, 4, 192)    576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 4, 4, 192)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 4, 4, 192)    0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 4, 4, 192)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 4, 4, 192)    0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 4, 4, 768)    0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 4, 4, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 4, 4, 160)    480         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 4, 4, 160)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 4, 4, 160)    179200      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 4, 4, 160)    480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 4, 4, 160)    0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 4, 4, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 4, 4, 160)    179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 4, 4, 160)    480         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 4, 4, 160)    480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 4, 4, 160)    0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 4, 4, 160)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 4, 4, 160)    179200      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 4, 4, 160)    179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 4, 4, 160)    480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 4, 4, 160)    480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 4, 4, 160)    0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 4, 4, 160)    0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 4, 4, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 4, 4, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 4, 4, 192)    215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 4, 4, 192)    215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 4, 4, 192)    147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 4, 4, 192)    576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 4, 4, 192)    576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 4, 4, 192)    576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 4, 4, 192)    576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 4, 4, 192)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 4, 4, 192)    0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 4, 4, 192)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 4, 4, 192)    0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 4, 4, 768)    0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 4, 4, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 4, 4, 192)    576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 4, 4, 192)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 4, 4, 192)    258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 4, 4, 192)    576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 4, 4, 192)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 4, 4, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 4, 4, 192)    258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 4, 4, 192)    576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 4, 4, 192)    576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 4, 4, 192)    0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 4, 4, 192)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 4, 4, 192)    258048      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 4, 4, 192)    258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 4, 4, 192)    576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 4, 4, 192)    576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 4, 4, 192)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 4, 4, 192)    0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 4, 4, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 4, 4, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 4, 4, 192)    258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 4, 4, 192)    258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 4, 4, 192)    147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 4, 4, 192)    576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 4, 4, 192)    576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 4, 4, 192)    576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 4, 4, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 4, 4, 192)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 4, 4, 192)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 4, 4, 192)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 4, 4, 192)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 4, 4, 768)    0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 4, 4, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 4, 4, 192)    576         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 4, 4, 192)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 4, 4, 192)    258048      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 4, 4, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 4, 4, 192)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 4, 4, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 4, 4, 192)    258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 4, 4, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 4, 4, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 4, 4, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 4, 4, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 1, 1, 320)    552960      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 1, 1, 192)    331776      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 1, 1, 320)    960         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 1, 1, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 1, 1, 320)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 1, 1, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 1, 1, 1280)   0           activation_165[0][0]             \n",
      "                                                                 activation_169[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 1, 1, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 1, 1, 448)    1344        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 1, 1, 448)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 1, 1, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 1, 1, 384)    1548288     activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 1, 1, 384)    1152        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 1, 1, 384)    1152        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 1, 1, 384)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 1, 1, 384)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 1, 1, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 1, 1, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 1, 1, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 1, 1, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 1, 1, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 1, 1, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 1, 1, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 1, 1, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 1, 1, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 1, 1, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 1, 1, 192)    245760      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 1, 1, 320)    960         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 1, 1, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 1, 1, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 1, 1, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 1, 1, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 1, 1, 192)    576         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 1, 1, 320)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 1, 1, 768)    0           activation_172[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 1, 768)    0           activation_176[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 1, 1, 192)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 1, 1, 2048)   0           activation_170[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 1, 1, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 1, 1, 448)    1344        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 1, 1, 448)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 1, 1, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 1, 1, 384)    1548288     activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 1, 1, 384)    1152        conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 1, 1, 384)    1152        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 1, 1, 384)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 1, 1, 384)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 1, 1, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 1, 1, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 1, 1, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 1, 1, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 1, 1, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 1, 1, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 1, 1, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 1, 1, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 1, 1, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 1, 1, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 1, 1, 192)    393216      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 1, 1, 320)    960         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 1, 1, 384)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 1, 1, 384)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 1, 1, 384)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 1, 1, 384)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 1, 1, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 1, 1, 320)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 1, 1, 768)    0           activation_181[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1, 1, 768)    0           activation_185[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 1, 1, 192)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 1, 1, 2048)   0           activation_179[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_187[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#remove fully-connected layers at the top of the CNN\n",
    "\n",
    "inc_model = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet', include_top=False, input_shape=(100,100,3))\n",
    "\n",
    "inc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8c0ae44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer True\n",
      "1 Conv2D True\n",
      "2 BatchNormalization True\n",
      "3 Activation True\n",
      "4 Conv2D True\n",
      "5 BatchNormalization True\n",
      "6 Activation True\n",
      "7 Conv2D True\n",
      "8 BatchNormalization True\n",
      "9 Activation True\n",
      "10 MaxPooling2D True\n",
      "11 Conv2D True\n",
      "12 BatchNormalization True\n",
      "13 Activation True\n",
      "14 Conv2D True\n",
      "15 BatchNormalization True\n",
      "16 Activation True\n",
      "17 MaxPooling2D True\n",
      "18 Conv2D True\n",
      "19 BatchNormalization True\n",
      "20 Activation True\n",
      "21 Conv2D True\n",
      "22 Conv2D True\n",
      "23 BatchNormalization True\n",
      "24 BatchNormalization True\n",
      "25 Activation True\n",
      "26 Activation True\n",
      "27 AveragePooling2D True\n",
      "28 Conv2D True\n",
      "29 Conv2D True\n",
      "30 Conv2D True\n",
      "31 Conv2D True\n",
      "32 BatchNormalization True\n",
      "33 BatchNormalization True\n",
      "34 BatchNormalization True\n",
      "35 BatchNormalization True\n",
      "36 Activation True\n",
      "37 Activation True\n",
      "38 Activation True\n",
      "39 Activation True\n",
      "40 Concatenate True\n",
      "41 Conv2D True\n",
      "42 BatchNormalization True\n",
      "43 Activation True\n",
      "44 Conv2D True\n",
      "45 Conv2D True\n",
      "46 BatchNormalization True\n",
      "47 BatchNormalization True\n",
      "48 Activation True\n",
      "49 Activation True\n",
      "50 AveragePooling2D True\n",
      "51 Conv2D True\n",
      "52 Conv2D True\n",
      "53 Conv2D True\n",
      "54 Conv2D True\n",
      "55 BatchNormalization True\n",
      "56 BatchNormalization True\n",
      "57 BatchNormalization True\n",
      "58 BatchNormalization True\n",
      "59 Activation True\n",
      "60 Activation True\n",
      "61 Activation True\n",
      "62 Activation True\n",
      "63 Concatenate True\n",
      "64 Conv2D True\n",
      "65 BatchNormalization True\n",
      "66 Activation True\n",
      "67 Conv2D True\n",
      "68 Conv2D True\n",
      "69 BatchNormalization True\n",
      "70 BatchNormalization True\n",
      "71 Activation True\n",
      "72 Activation True\n",
      "73 AveragePooling2D True\n",
      "74 Conv2D True\n",
      "75 Conv2D True\n",
      "76 Conv2D True\n",
      "77 Conv2D True\n",
      "78 BatchNormalization True\n",
      "79 BatchNormalization True\n",
      "80 BatchNormalization True\n",
      "81 BatchNormalization True\n",
      "82 Activation True\n",
      "83 Activation True\n",
      "84 Activation True\n",
      "85 Activation True\n",
      "86 Concatenate True\n",
      "87 Conv2D True\n",
      "88 BatchNormalization True\n",
      "89 Activation True\n",
      "90 Conv2D True\n",
      "91 BatchNormalization True\n",
      "92 Activation True\n",
      "93 Conv2D True\n",
      "94 Conv2D True\n",
      "95 BatchNormalization True\n",
      "96 BatchNormalization True\n",
      "97 Activation True\n",
      "98 Activation True\n",
      "99 MaxPooling2D True\n",
      "100 Concatenate True\n",
      "101 Conv2D True\n",
      "102 BatchNormalization True\n",
      "103 Activation True\n",
      "104 Conv2D True\n",
      "105 BatchNormalization True\n",
      "106 Activation True\n",
      "107 Conv2D True\n",
      "108 Conv2D True\n",
      "109 BatchNormalization True\n",
      "110 BatchNormalization True\n",
      "111 Activation True\n",
      "112 Activation True\n",
      "113 Conv2D True\n",
      "114 Conv2D True\n",
      "115 BatchNormalization True\n",
      "116 BatchNormalization True\n",
      "117 Activation True\n",
      "118 Activation True\n",
      "119 AveragePooling2D True\n",
      "120 Conv2D True\n",
      "121 Conv2D True\n",
      "122 Conv2D True\n",
      "123 Conv2D True\n",
      "124 BatchNormalization True\n",
      "125 BatchNormalization True\n",
      "126 BatchNormalization True\n",
      "127 BatchNormalization True\n",
      "128 Activation True\n",
      "129 Activation True\n",
      "130 Activation True\n",
      "131 Activation True\n",
      "132 Concatenate True\n",
      "133 Conv2D True\n",
      "134 BatchNormalization True\n",
      "135 Activation True\n",
      "136 Conv2D True\n",
      "137 BatchNormalization True\n",
      "138 Activation True\n",
      "139 Conv2D True\n",
      "140 Conv2D True\n",
      "141 BatchNormalization True\n",
      "142 BatchNormalization True\n",
      "143 Activation True\n",
      "144 Activation True\n",
      "145 Conv2D True\n",
      "146 Conv2D True\n",
      "147 BatchNormalization True\n",
      "148 BatchNormalization True\n",
      "149 Activation True\n",
      "150 Activation True\n",
      "151 AveragePooling2D True\n",
      "152 Conv2D True\n",
      "153 Conv2D True\n",
      "154 Conv2D True\n",
      "155 Conv2D True\n",
      "156 BatchNormalization True\n",
      "157 BatchNormalization True\n",
      "158 BatchNormalization True\n",
      "159 BatchNormalization True\n",
      "160 Activation True\n",
      "161 Activation True\n",
      "162 Activation True\n",
      "163 Activation True\n",
      "164 Concatenate True\n",
      "165 Conv2D True\n",
      "166 BatchNormalization True\n",
      "167 Activation True\n",
      "168 Conv2D True\n",
      "169 BatchNormalization True\n",
      "170 Activation True\n",
      "171 Conv2D True\n",
      "172 Conv2D True\n",
      "173 BatchNormalization True\n",
      "174 BatchNormalization True\n",
      "175 Activation True\n",
      "176 Activation True\n",
      "177 Conv2D True\n",
      "178 Conv2D True\n",
      "179 BatchNormalization True\n",
      "180 BatchNormalization True\n",
      "181 Activation True\n",
      "182 Activation True\n",
      "183 AveragePooling2D True\n",
      "184 Conv2D True\n",
      "185 Conv2D True\n",
      "186 Conv2D True\n",
      "187 Conv2D True\n",
      "188 BatchNormalization True\n",
      "189 BatchNormalization True\n",
      "190 BatchNormalization True\n",
      "191 BatchNormalization True\n",
      "192 Activation True\n",
      "193 Activation True\n",
      "194 Activation True\n",
      "195 Activation True\n",
      "196 Concatenate True\n",
      "197 Conv2D True\n",
      "198 BatchNormalization True\n",
      "199 Activation True\n",
      "200 Conv2D True\n",
      "201 BatchNormalization True\n",
      "202 Activation True\n",
      "203 Conv2D True\n",
      "204 Conv2D True\n",
      "205 BatchNormalization True\n",
      "206 BatchNormalization True\n",
      "207 Activation True\n",
      "208 Activation True\n",
      "209 Conv2D True\n",
      "210 Conv2D True\n",
      "211 BatchNormalization True\n",
      "212 BatchNormalization True\n",
      "213 Activation True\n",
      "214 Activation True\n",
      "215 AveragePooling2D True\n",
      "216 Conv2D True\n",
      "217 Conv2D True\n",
      "218 Conv2D True\n",
      "219 Conv2D True\n",
      "220 BatchNormalization True\n",
      "221 BatchNormalization True\n",
      "222 BatchNormalization True\n",
      "223 BatchNormalization True\n",
      "224 Activation True\n",
      "225 Activation True\n",
      "226 Activation True\n",
      "227 Activation True\n",
      "228 Concatenate True\n",
      "229 Conv2D True\n",
      "230 BatchNormalization True\n",
      "231 Activation True\n",
      "232 Conv2D True\n",
      "233 BatchNormalization True\n",
      "234 Activation True\n",
      "235 Conv2D True\n",
      "236 Conv2D True\n",
      "237 BatchNormalization True\n",
      "238 BatchNormalization True\n",
      "239 Activation True\n",
      "240 Activation True\n",
      "241 Conv2D True\n",
      "242 Conv2D True\n",
      "243 BatchNormalization True\n",
      "244 BatchNormalization True\n",
      "245 Activation True\n",
      "246 Activation True\n",
      "247 MaxPooling2D True\n",
      "248 Concatenate True\n",
      "249 Conv2D True\n",
      "250 BatchNormalization True\n",
      "251 Activation True\n",
      "252 Conv2D True\n",
      "253 Conv2D True\n",
      "254 BatchNormalization True\n",
      "255 BatchNormalization True\n",
      "256 Activation True\n",
      "257 Activation True\n",
      "258 Conv2D True\n",
      "259 Conv2D True\n",
      "260 Conv2D True\n",
      "261 Conv2D True\n",
      "262 AveragePooling2D True\n",
      "263 Conv2D True\n",
      "264 BatchNormalization True\n",
      "265 BatchNormalization True\n",
      "266 BatchNormalization True\n",
      "267 BatchNormalization True\n",
      "268 Conv2D True\n",
      "269 BatchNormalization True\n",
      "270 Activation True\n",
      "271 Activation True\n",
      "272 Activation True\n",
      "273 Activation True\n",
      "274 BatchNormalization True\n",
      "275 Activation True\n",
      "276 Concatenate True\n",
      "277 Concatenate True\n",
      "278 Activation True\n",
      "279 Concatenate True\n",
      "280 Conv2D True\n",
      "281 BatchNormalization True\n",
      "282 Activation True\n",
      "283 Conv2D True\n",
      "284 Conv2D True\n",
      "285 BatchNormalization True\n",
      "286 BatchNormalization True\n",
      "287 Activation True\n",
      "288 Activation True\n",
      "289 Conv2D True\n",
      "290 Conv2D True\n",
      "291 Conv2D True\n",
      "292 Conv2D True\n",
      "293 AveragePooling2D True\n",
      "294 Conv2D True\n",
      "295 BatchNormalization True\n",
      "296 BatchNormalization True\n",
      "297 BatchNormalization True\n",
      "298 BatchNormalization True\n",
      "299 Conv2D True\n",
      "300 BatchNormalization True\n",
      "301 Activation True\n",
      "302 Activation True\n",
      "303 Activation True\n",
      "304 Activation True\n",
      "305 BatchNormalization True\n",
      "306 Activation True\n",
      "307 Concatenate True\n",
      "308 Concatenate True\n",
      "309 Activation True\n",
      "310 Concatenate True\n"
     ]
    }
   ],
   "source": [
    "#ensure all the layers are trainable\n",
    "for (i, layer) in enumerate(inc_model.layers):\n",
    "    print(str(i)+\" \"+layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c2f1eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D False\n",
      "2 BatchNormalization False\n",
      "3 Activation False\n",
      "4 Conv2D False\n",
      "5 BatchNormalization False\n",
      "6 Activation False\n",
      "7 Conv2D False\n",
      "8 BatchNormalization False\n",
      "9 Activation False\n",
      "10 MaxPooling2D False\n",
      "11 Conv2D False\n",
      "12 BatchNormalization False\n",
      "13 Activation False\n",
      "14 Conv2D False\n",
      "15 BatchNormalization False\n",
      "16 Activation False\n",
      "17 MaxPooling2D False\n",
      "18 Conv2D False\n",
      "19 BatchNormalization False\n",
      "20 Activation False\n",
      "21 Conv2D False\n",
      "22 Conv2D False\n",
      "23 BatchNormalization False\n",
      "24 BatchNormalization False\n",
      "25 Activation False\n",
      "26 Activation False\n",
      "27 AveragePooling2D False\n",
      "28 Conv2D False\n",
      "29 Conv2D False\n",
      "30 Conv2D False\n",
      "31 Conv2D False\n",
      "32 BatchNormalization False\n",
      "33 BatchNormalization False\n",
      "34 BatchNormalization False\n",
      "35 BatchNormalization False\n",
      "36 Activation False\n",
      "37 Activation False\n",
      "38 Activation False\n",
      "39 Activation False\n",
      "40 Concatenate False\n",
      "41 Conv2D False\n",
      "42 BatchNormalization False\n",
      "43 Activation False\n",
      "44 Conv2D False\n",
      "45 Conv2D False\n",
      "46 BatchNormalization False\n",
      "47 BatchNormalization False\n",
      "48 Activation False\n",
      "49 Activation False\n",
      "50 AveragePooling2D False\n",
      "51 Conv2D False\n",
      "52 Conv2D False\n",
      "53 Conv2D False\n",
      "54 Conv2D False\n",
      "55 BatchNormalization False\n",
      "56 BatchNormalization False\n",
      "57 BatchNormalization False\n",
      "58 BatchNormalization False\n",
      "59 Activation False\n",
      "60 Activation False\n",
      "61 Activation False\n",
      "62 Activation False\n",
      "63 Concatenate False\n",
      "64 Conv2D False\n",
      "65 BatchNormalization False\n",
      "66 Activation False\n",
      "67 Conv2D False\n",
      "68 Conv2D False\n",
      "69 BatchNormalization False\n",
      "70 BatchNormalization False\n",
      "71 Activation False\n",
      "72 Activation False\n",
      "73 AveragePooling2D False\n",
      "74 Conv2D False\n",
      "75 Conv2D False\n",
      "76 Conv2D False\n",
      "77 Conv2D False\n",
      "78 BatchNormalization False\n",
      "79 BatchNormalization False\n",
      "80 BatchNormalization False\n",
      "81 BatchNormalization False\n",
      "82 Activation False\n",
      "83 Activation False\n",
      "84 Activation False\n",
      "85 Activation False\n",
      "86 Concatenate False\n",
      "87 Conv2D False\n",
      "88 BatchNormalization False\n",
      "89 Activation False\n",
      "90 Conv2D False\n",
      "91 BatchNormalization False\n",
      "92 Activation False\n",
      "93 Conv2D False\n",
      "94 Conv2D False\n",
      "95 BatchNormalization False\n",
      "96 BatchNormalization False\n",
      "97 Activation False\n",
      "98 Activation False\n",
      "99 MaxPooling2D False\n",
      "100 Concatenate False\n",
      "101 Conv2D False\n",
      "102 BatchNormalization False\n",
      "103 Activation False\n",
      "104 Conv2D False\n",
      "105 BatchNormalization False\n",
      "106 Activation False\n",
      "107 Conv2D False\n",
      "108 Conv2D False\n",
      "109 BatchNormalization False\n",
      "110 BatchNormalization False\n",
      "111 Activation False\n",
      "112 Activation False\n",
      "113 Conv2D False\n",
      "114 Conv2D False\n",
      "115 BatchNormalization False\n",
      "116 BatchNormalization False\n",
      "117 Activation False\n",
      "118 Activation False\n",
      "119 AveragePooling2D False\n",
      "120 Conv2D False\n",
      "121 Conv2D False\n",
      "122 Conv2D False\n",
      "123 Conv2D False\n",
      "124 BatchNormalization False\n",
      "125 BatchNormalization False\n",
      "126 BatchNormalization False\n",
      "127 BatchNormalization False\n",
      "128 Activation False\n",
      "129 Activation False\n",
      "130 Activation False\n",
      "131 Activation False\n",
      "132 Concatenate False\n",
      "133 Conv2D False\n",
      "134 BatchNormalization False\n",
      "135 Activation False\n",
      "136 Conv2D False\n",
      "137 BatchNormalization False\n",
      "138 Activation False\n",
      "139 Conv2D False\n",
      "140 Conv2D False\n",
      "141 BatchNormalization False\n",
      "142 BatchNormalization False\n",
      "143 Activation False\n",
      "144 Activation False\n",
      "145 Conv2D False\n",
      "146 Conv2D False\n",
      "147 BatchNormalization False\n",
      "148 BatchNormalization False\n",
      "149 Activation False\n",
      "150 Activation False\n",
      "151 AveragePooling2D False\n",
      "152 Conv2D False\n",
      "153 Conv2D False\n",
      "154 Conv2D False\n",
      "155 Conv2D False\n",
      "156 BatchNormalization False\n",
      "157 BatchNormalization False\n",
      "158 BatchNormalization False\n",
      "159 BatchNormalization False\n",
      "160 Activation False\n",
      "161 Activation False\n",
      "162 Activation False\n",
      "163 Activation False\n",
      "164 Concatenate False\n",
      "165 Conv2D False\n",
      "166 BatchNormalization False\n",
      "167 Activation False\n",
      "168 Conv2D False\n",
      "169 BatchNormalization False\n",
      "170 Activation False\n",
      "171 Conv2D False\n",
      "172 Conv2D False\n",
      "173 BatchNormalization False\n",
      "174 BatchNormalization False\n",
      "175 Activation False\n",
      "176 Activation False\n",
      "177 Conv2D False\n",
      "178 Conv2D False\n",
      "179 BatchNormalization False\n",
      "180 BatchNormalization False\n",
      "181 Activation False\n",
      "182 Activation False\n",
      "183 AveragePooling2D False\n",
      "184 Conv2D False\n",
      "185 Conv2D False\n",
      "186 Conv2D False\n",
      "187 Conv2D False\n",
      "188 BatchNormalization False\n",
      "189 BatchNormalization False\n",
      "190 BatchNormalization False\n",
      "191 BatchNormalization False\n",
      "192 Activation False\n",
      "193 Activation False\n",
      "194 Activation False\n",
      "195 Activation False\n",
      "196 Concatenate False\n",
      "197 Conv2D False\n",
      "198 BatchNormalization False\n",
      "199 Activation False\n",
      "200 Conv2D False\n",
      "201 BatchNormalization False\n",
      "202 Activation False\n",
      "203 Conv2D False\n",
      "204 Conv2D False\n",
      "205 BatchNormalization False\n",
      "206 BatchNormalization False\n",
      "207 Activation False\n",
      "208 Activation False\n",
      "209 Conv2D False\n",
      "210 Conv2D False\n",
      "211 BatchNormalization False\n",
      "212 BatchNormalization False\n",
      "213 Activation False\n",
      "214 Activation False\n",
      "215 AveragePooling2D False\n",
      "216 Conv2D False\n",
      "217 Conv2D False\n",
      "218 Conv2D False\n",
      "219 Conv2D False\n",
      "220 BatchNormalization False\n",
      "221 BatchNormalization False\n",
      "222 BatchNormalization False\n",
      "223 BatchNormalization False\n",
      "224 Activation False\n",
      "225 Activation False\n",
      "226 Activation False\n",
      "227 Activation False\n",
      "228 Concatenate False\n",
      "229 Conv2D False\n",
      "230 BatchNormalization False\n",
      "231 Activation False\n",
      "232 Conv2D False\n",
      "233 BatchNormalization False\n",
      "234 Activation False\n",
      "235 Conv2D False\n",
      "236 Conv2D False\n",
      "237 BatchNormalization False\n",
      "238 BatchNormalization False\n",
      "239 Activation False\n",
      "240 Activation False\n",
      "241 Conv2D False\n",
      "242 Conv2D False\n",
      "243 BatchNormalization False\n",
      "244 BatchNormalization False\n",
      "245 Activation False\n",
      "246 Activation False\n",
      "247 MaxPooling2D False\n",
      "248 Concatenate False\n",
      "249 Conv2D False\n",
      "250 BatchNormalization False\n",
      "251 Activation False\n",
      "252 Conv2D False\n",
      "253 Conv2D False\n",
      "254 BatchNormalization False\n",
      "255 BatchNormalization False\n",
      "256 Activation False\n",
      "257 Activation False\n",
      "258 Conv2D False\n",
      "259 Conv2D False\n",
      "260 Conv2D False\n",
      "261 Conv2D False\n",
      "262 AveragePooling2D False\n",
      "263 Conv2D False\n",
      "264 BatchNormalization False\n",
      "265 BatchNormalization False\n",
      "266 BatchNormalization False\n",
      "267 BatchNormalization False\n",
      "268 Conv2D False\n",
      "269 BatchNormalization False\n",
      "270 Activation False\n",
      "271 Activation False\n",
      "272 Activation False\n",
      "273 Activation False\n",
      "274 BatchNormalization False\n",
      "275 Activation False\n",
      "276 Concatenate False\n",
      "277 Concatenate False\n",
      "278 Activation False\n",
      "279 Concatenate False\n",
      "280 Conv2D False\n",
      "281 BatchNormalization False\n",
      "282 Activation False\n",
      "283 Conv2D False\n",
      "284 Conv2D False\n",
      "285 BatchNormalization False\n",
      "286 BatchNormalization False\n",
      "287 Activation False\n",
      "288 Activation False\n",
      "289 Conv2D False\n",
      "290 Conv2D False\n",
      "291 Conv2D False\n",
      "292 Conv2D False\n",
      "293 AveragePooling2D False\n",
      "294 Conv2D False\n",
      "295 BatchNormalization False\n",
      "296 BatchNormalization False\n",
      "297 BatchNormalization False\n",
      "298 BatchNormalization False\n",
      "299 Conv2D False\n",
      "300 BatchNormalization False\n",
      "301 Activation False\n",
      "302 Activation False\n",
      "303 Activation False\n",
      "304 Activation False\n",
      "305 BatchNormalization False\n",
      "306 Activation False\n",
      "307 Concatenate False\n",
      "308 Concatenate False\n",
      "309 Activation False\n",
      "310 Concatenate False\n"
     ]
    }
   ],
   "source": [
    "#freeze the trainable layers\n",
    "for layer in inc_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for (i, layer) in enumerate(inc_model.layers):\n",
    "    print(str(i)+\" \"+layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a232026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create a fully-connected head for the CNN\n",
    "def CNNHead(bottom, num_classes):\n",
    "    top = bottom.output\n",
    "    top = Flatten(name='flatten')(top) #add flatten layer to top\n",
    "    top = Dense(256, activation='relu')(top)\n",
    "    top = Dropout(0.3)(top)\n",
    "    top = Dense(num_classes, activation='softmax')(top)\n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc48d369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 49, 49, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 49, 49, 32)   96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 49, 49, 32)   0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 47, 47, 32)   9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 47, 47, 32)   96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 47, 47, 32)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 47, 47, 64)   18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 47, 47, 64)   192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 47, 47, 64)   0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 23, 23, 64)   0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 23, 23, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 23, 23, 80)   240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 23, 23, 80)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 21, 21, 192)  138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 21, 21, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 21, 21, 192)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 10, 192)  0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 10, 10, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 10, 10, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 10, 10, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 10, 10, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 10, 10, 96)   55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 10, 10, 48)   144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 10, 10, 96)   288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 10, 10, 48)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 10, 10, 96)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 10, 10, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 10, 10, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 10, 10, 64)   76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 10, 10, 96)   82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 10, 10, 32)   6144        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 10, 10, 64)   192         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 10, 10, 64)   192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 10, 10, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 10, 10, 32)   96          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 10, 10, 64)   0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 10, 10, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 10, 10, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 10, 10, 32)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 10, 10, 256)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 10, 10, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 10, 10, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 10, 10, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 10, 10, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 10, 10, 96)   55296       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 10, 10, 48)   144         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 10, 10, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 10, 10, 48)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 10, 10, 96)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 10, 10, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 10, 10, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 10, 10, 64)   76800       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 10, 10, 96)   82944       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 10, 10, 64)   16384       average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 10, 10, 64)   192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 10, 10, 64)   192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 10, 10, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 10, 10, 64)   192         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 10, 10, 64)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 10, 10, 64)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 10, 10, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 10, 10, 64)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 10, 10, 288)  0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 10, 10, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 10, 10, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 10, 10, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 10, 10, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 10, 10, 96)   55296       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 10, 10, 48)   144         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 10, 10, 96)   288         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 10, 10, 48)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 10, 10, 96)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 10, 10, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 10, 10, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 10, 10, 64)   76800       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 10, 10, 96)   82944       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 10, 10, 64)   18432       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 10, 10, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 10, 10, 64)   192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 10, 10, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 10, 10, 64)   192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 10, 10, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 10, 10, 64)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 10, 10, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 10, 10, 64)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 10, 10, 288)  0           activation_113[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 10, 10, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 10, 10, 64)   192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 10, 10, 64)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 10, 10, 96)   55296       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 10, 10, 96)   288         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 10, 10, 96)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 4, 4, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 4, 4, 96)     82944       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 4, 4, 384)    1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 4, 4, 96)     288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 4, 4, 384)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 4, 4, 96)     0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 4, 4, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 4, 4, 768)    0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 4, 4, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 4, 4, 128)    384         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 4, 4, 128)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 4, 4, 128)    114688      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 4, 4, 128)    384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 4, 4, 128)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 4, 4, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 4, 4, 128)    114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 4, 4, 128)    384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 4, 4, 128)    384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 4, 4, 128)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 4, 4, 128)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 4, 4, 128)    114688      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 4, 4, 128)    114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 4, 4, 128)    384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 4, 4, 128)    384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 4, 4, 128)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 4, 4, 128)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 4, 4, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 4, 4, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 4, 4, 192)    172032      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 4, 4, 192)    172032      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 4, 4, 192)    147456      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 4, 4, 192)    576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 4, 4, 192)    576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 4, 4, 192)    576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 4, 4, 192)    576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 4, 4, 192)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 4, 4, 192)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 4, 4, 192)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 4, 4, 192)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 4, 4, 768)    0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 4, 4, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 4, 4, 160)    480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 4, 4, 160)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 4, 4, 160)    179200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 4, 4, 160)    480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 4, 4, 160)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 4, 4, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 4, 4, 160)    179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 4, 4, 160)    480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 4, 4, 160)    480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 4, 4, 160)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 4, 4, 160)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 4, 4, 160)    179200      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 4, 4, 160)    179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 4, 4, 160)    480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 4, 4, 160)    480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 4, 4, 160)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 4, 4, 160)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 4, 4, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 4, 4, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 4, 4, 192)    215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 4, 4, 192)    215040      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 4, 4, 192)    147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 4, 4, 192)    576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 4, 4, 192)    576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 4, 4, 192)    576         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 4, 4, 192)    576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 4, 4, 192)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 4, 4, 192)    0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 4, 4, 192)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 4, 4, 192)    0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 4, 4, 768)    0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 4, 4, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 4, 4, 160)    480         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 4, 4, 160)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 4, 4, 160)    179200      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 4, 4, 160)    480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 4, 4, 160)    0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 4, 4, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 4, 4, 160)    179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 4, 4, 160)    480         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 4, 4, 160)    480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 4, 4, 160)    0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 4, 4, 160)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 4, 4, 160)    179200      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 4, 4, 160)    179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 4, 4, 160)    480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 4, 4, 160)    480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 4, 4, 160)    0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 4, 4, 160)    0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 4, 4, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 4, 4, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 4, 4, 192)    215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 4, 4, 192)    215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 4, 4, 192)    147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 4, 4, 192)    576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 4, 4, 192)    576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 4, 4, 192)    576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 4, 4, 192)    576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 4, 4, 192)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 4, 4, 192)    0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 4, 4, 192)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 4, 4, 192)    0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 4, 4, 768)    0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 4, 4, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 4, 4, 192)    576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 4, 4, 192)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 4, 4, 192)    258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 4, 4, 192)    576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 4, 4, 192)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 4, 4, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 4, 4, 192)    258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 4, 4, 192)    576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 4, 4, 192)    576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 4, 4, 192)    0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 4, 4, 192)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 4, 4, 192)    258048      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 4, 4, 192)    258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 4, 4, 192)    576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 4, 4, 192)    576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 4, 4, 192)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 4, 4, 192)    0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 4, 4, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 4, 4, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 4, 4, 192)    258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 4, 4, 192)    258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 4, 4, 192)    147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 4, 4, 192)    576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 4, 4, 192)    576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 4, 4, 192)    576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 4, 4, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 4, 4, 192)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 4, 4, 192)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 4, 4, 192)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 4, 4, 192)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 4, 4, 768)    0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 4, 4, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 4, 4, 192)    576         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 4, 4, 192)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 4, 4, 192)    258048      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 4, 4, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 4, 4, 192)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 4, 4, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 4, 4, 192)    258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 4, 4, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 4, 4, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 4, 4, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 4, 4, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 1, 1, 320)    552960      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 1, 1, 192)    331776      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 1, 1, 320)    960         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 1, 1, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 1, 1, 320)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 1, 1, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 1, 1, 1280)   0           activation_165[0][0]             \n",
      "                                                                 activation_169[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 1, 1, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 1, 1, 448)    1344        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 1, 1, 448)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 1, 1, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 1, 1, 384)    1548288     activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 1, 1, 384)    1152        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 1, 1, 384)    1152        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 1, 1, 384)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 1, 1, 384)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 1, 1, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 1, 1, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 1, 1, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 1, 1, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 1, 1, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 1, 1, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 1, 1, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 1, 1, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 1, 1, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 1, 1, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 1, 1, 192)    245760      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 1, 1, 320)    960         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 1, 1, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 1, 1, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 1, 1, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 1, 1, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 1, 1, 192)    576         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 1, 1, 320)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 1, 1, 768)    0           activation_172[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 1, 768)    0           activation_176[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 1, 1, 192)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 1, 1, 2048)   0           activation_170[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 1, 1, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 1, 1, 448)    1344        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 1, 1, 448)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 1, 1, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 1, 1, 384)    1548288     activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 1, 1, 384)    1152        conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 1, 1, 384)    1152        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 1, 1, 384)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 1, 1, 384)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 1, 1, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 1, 1, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 1, 1, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 1, 1, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 1, 1, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 1, 1, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 1, 1, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 1, 1, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 1, 1, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 1, 1, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 1, 1, 192)    393216      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 1, 1, 320)    960         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 1, 1, 384)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 1, 1, 384)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 1, 1, 384)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 1, 1, 384)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 1, 1, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 1, 1, 320)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 1, 1, 768)    0           activation_181[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1, 1, 768)    0           activation_185[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 1, 1, 192)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 1, 1, 2048)   0           activation_179[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            1285        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,328,613\n",
      "Trainable params: 525,829\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#add the fully-connected head on top of the VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "FCHead = CNNHead(inc_model, 5)\n",
    "\n",
    "model = Model(inputs=inc_model.input, outputs=FCHead)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d04b0ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D False\n",
      "2 BatchNormalization False\n",
      "3 Activation False\n",
      "4 Conv2D False\n",
      "5 BatchNormalization False\n",
      "6 Activation False\n",
      "7 Conv2D False\n",
      "8 BatchNormalization False\n",
      "9 Activation False\n",
      "10 MaxPooling2D False\n",
      "11 Conv2D False\n",
      "12 BatchNormalization False\n",
      "13 Activation False\n",
      "14 Conv2D False\n",
      "15 BatchNormalization False\n",
      "16 Activation False\n",
      "17 MaxPooling2D False\n",
      "18 Conv2D False\n",
      "19 BatchNormalization False\n",
      "20 Activation False\n",
      "21 Conv2D False\n",
      "22 Conv2D False\n",
      "23 BatchNormalization False\n",
      "24 BatchNormalization False\n",
      "25 Activation False\n",
      "26 Activation False\n",
      "27 AveragePooling2D False\n",
      "28 Conv2D False\n",
      "29 Conv2D False\n",
      "30 Conv2D False\n",
      "31 Conv2D False\n",
      "32 BatchNormalization False\n",
      "33 BatchNormalization False\n",
      "34 BatchNormalization False\n",
      "35 BatchNormalization False\n",
      "36 Activation False\n",
      "37 Activation False\n",
      "38 Activation False\n",
      "39 Activation False\n",
      "40 Concatenate False\n",
      "41 Conv2D False\n",
      "42 BatchNormalization False\n",
      "43 Activation False\n",
      "44 Conv2D False\n",
      "45 Conv2D False\n",
      "46 BatchNormalization False\n",
      "47 BatchNormalization False\n",
      "48 Activation False\n",
      "49 Activation False\n",
      "50 AveragePooling2D False\n",
      "51 Conv2D False\n",
      "52 Conv2D False\n",
      "53 Conv2D False\n",
      "54 Conv2D False\n",
      "55 BatchNormalization False\n",
      "56 BatchNormalization False\n",
      "57 BatchNormalization False\n",
      "58 BatchNormalization False\n",
      "59 Activation False\n",
      "60 Activation False\n",
      "61 Activation False\n",
      "62 Activation False\n",
      "63 Concatenate False\n",
      "64 Conv2D False\n",
      "65 BatchNormalization False\n",
      "66 Activation False\n",
      "67 Conv2D False\n",
      "68 Conv2D False\n",
      "69 BatchNormalization False\n",
      "70 BatchNormalization False\n",
      "71 Activation False\n",
      "72 Activation False\n",
      "73 AveragePooling2D False\n",
      "74 Conv2D False\n",
      "75 Conv2D False\n",
      "76 Conv2D False\n",
      "77 Conv2D False\n",
      "78 BatchNormalization False\n",
      "79 BatchNormalization False\n",
      "80 BatchNormalization False\n",
      "81 BatchNormalization False\n",
      "82 Activation False\n",
      "83 Activation False\n",
      "84 Activation False\n",
      "85 Activation False\n",
      "86 Concatenate False\n",
      "87 Conv2D False\n",
      "88 BatchNormalization False\n",
      "89 Activation False\n",
      "90 Conv2D False\n",
      "91 BatchNormalization False\n",
      "92 Activation False\n",
      "93 Conv2D False\n",
      "94 Conv2D False\n",
      "95 BatchNormalization False\n",
      "96 BatchNormalization False\n",
      "97 Activation False\n",
      "98 Activation False\n",
      "99 MaxPooling2D False\n",
      "100 Concatenate False\n",
      "101 Conv2D False\n",
      "102 BatchNormalization False\n",
      "103 Activation False\n",
      "104 Conv2D False\n",
      "105 BatchNormalization False\n",
      "106 Activation False\n",
      "107 Conv2D False\n",
      "108 Conv2D False\n",
      "109 BatchNormalization False\n",
      "110 BatchNormalization False\n",
      "111 Activation False\n",
      "112 Activation False\n",
      "113 Conv2D False\n",
      "114 Conv2D False\n",
      "115 BatchNormalization False\n",
      "116 BatchNormalization False\n",
      "117 Activation False\n",
      "118 Activation False\n",
      "119 AveragePooling2D False\n",
      "120 Conv2D False\n",
      "121 Conv2D False\n",
      "122 Conv2D False\n",
      "123 Conv2D False\n",
      "124 BatchNormalization False\n",
      "125 BatchNormalization False\n",
      "126 BatchNormalization False\n",
      "127 BatchNormalization False\n",
      "128 Activation False\n",
      "129 Activation False\n",
      "130 Activation False\n",
      "131 Activation False\n",
      "132 Concatenate False\n",
      "133 Conv2D False\n",
      "134 BatchNormalization False\n",
      "135 Activation False\n",
      "136 Conv2D False\n",
      "137 BatchNormalization False\n",
      "138 Activation False\n",
      "139 Conv2D False\n",
      "140 Conv2D False\n",
      "141 BatchNormalization False\n",
      "142 BatchNormalization False\n",
      "143 Activation False\n",
      "144 Activation False\n",
      "145 Conv2D False\n",
      "146 Conv2D False\n",
      "147 BatchNormalization False\n",
      "148 BatchNormalization False\n",
      "149 Activation False\n",
      "150 Activation False\n",
      "151 AveragePooling2D False\n",
      "152 Conv2D False\n",
      "153 Conv2D False\n",
      "154 Conv2D False\n",
      "155 Conv2D False\n",
      "156 BatchNormalization False\n",
      "157 BatchNormalization False\n",
      "158 BatchNormalization False\n",
      "159 BatchNormalization False\n",
      "160 Activation False\n",
      "161 Activation False\n",
      "162 Activation False\n",
      "163 Activation False\n",
      "164 Concatenate False\n",
      "165 Conv2D False\n",
      "166 BatchNormalization False\n",
      "167 Activation False\n",
      "168 Conv2D False\n",
      "169 BatchNormalization False\n",
      "170 Activation False\n",
      "171 Conv2D False\n",
      "172 Conv2D False\n",
      "173 BatchNormalization False\n",
      "174 BatchNormalization False\n",
      "175 Activation False\n",
      "176 Activation False\n",
      "177 Conv2D False\n",
      "178 Conv2D False\n",
      "179 BatchNormalization False\n",
      "180 BatchNormalization False\n",
      "181 Activation False\n",
      "182 Activation False\n",
      "183 AveragePooling2D False\n",
      "184 Conv2D False\n",
      "185 Conv2D False\n",
      "186 Conv2D False\n",
      "187 Conv2D False\n",
      "188 BatchNormalization False\n",
      "189 BatchNormalization False\n",
      "190 BatchNormalization False\n",
      "191 BatchNormalization False\n",
      "192 Activation False\n",
      "193 Activation False\n",
      "194 Activation False\n",
      "195 Activation False\n",
      "196 Concatenate False\n",
      "197 Conv2D False\n",
      "198 BatchNormalization False\n",
      "199 Activation False\n",
      "200 Conv2D False\n",
      "201 BatchNormalization False\n",
      "202 Activation False\n",
      "203 Conv2D False\n",
      "204 Conv2D False\n",
      "205 BatchNormalization False\n",
      "206 BatchNormalization False\n",
      "207 Activation False\n",
      "208 Activation False\n",
      "209 Conv2D False\n",
      "210 Conv2D False\n",
      "211 BatchNormalization False\n",
      "212 BatchNormalization False\n",
      "213 Activation False\n",
      "214 Activation False\n",
      "215 AveragePooling2D False\n",
      "216 Conv2D False\n",
      "217 Conv2D False\n",
      "218 Conv2D False\n",
      "219 Conv2D False\n",
      "220 BatchNormalization False\n",
      "221 BatchNormalization False\n",
      "222 BatchNormalization False\n",
      "223 BatchNormalization False\n",
      "224 Activation False\n",
      "225 Activation False\n",
      "226 Activation False\n",
      "227 Activation False\n",
      "228 Concatenate False\n",
      "229 Conv2D False\n",
      "230 BatchNormalization False\n",
      "231 Activation False\n",
      "232 Conv2D False\n",
      "233 BatchNormalization False\n",
      "234 Activation False\n",
      "235 Conv2D False\n",
      "236 Conv2D False\n",
      "237 BatchNormalization False\n",
      "238 BatchNormalization False\n",
      "239 Activation False\n",
      "240 Activation False\n",
      "241 Conv2D False\n",
      "242 Conv2D False\n",
      "243 BatchNormalization False\n",
      "244 BatchNormalization False\n",
      "245 Activation False\n",
      "246 Activation False\n",
      "247 MaxPooling2D False\n",
      "248 Concatenate False\n",
      "249 Conv2D False\n",
      "250 BatchNormalization False\n",
      "251 Activation False\n",
      "252 Conv2D False\n",
      "253 Conv2D False\n",
      "254 BatchNormalization False\n",
      "255 BatchNormalization False\n",
      "256 Activation False\n",
      "257 Activation False\n",
      "258 Conv2D False\n",
      "259 Conv2D False\n",
      "260 Conv2D False\n",
      "261 Conv2D False\n",
      "262 AveragePooling2D False\n",
      "263 Conv2D False\n",
      "264 BatchNormalization False\n",
      "265 BatchNormalization False\n",
      "266 BatchNormalization False\n",
      "267 BatchNormalization False\n",
      "268 Conv2D False\n",
      "269 BatchNormalization False\n",
      "270 Activation False\n",
      "271 Activation False\n",
      "272 Activation False\n",
      "273 Activation False\n",
      "274 BatchNormalization False\n",
      "275 Activation False\n",
      "276 Concatenate False\n",
      "277 Concatenate False\n",
      "278 Activation False\n",
      "279 Concatenate False\n",
      "280 Conv2D False\n",
      "281 BatchNormalization False\n",
      "282 Activation False\n",
      "283 Conv2D False\n",
      "284 Conv2D False\n",
      "285 BatchNormalization False\n",
      "286 BatchNormalization False\n",
      "287 Activation False\n",
      "288 Activation False\n",
      "289 Conv2D False\n",
      "290 Conv2D False\n",
      "291 Conv2D False\n",
      "292 Conv2D False\n",
      "293 AveragePooling2D False\n",
      "294 Conv2D False\n",
      "295 BatchNormalization False\n",
      "296 BatchNormalization False\n",
      "297 BatchNormalization False\n",
      "298 BatchNormalization False\n",
      "299 Conv2D False\n",
      "300 BatchNormalization False\n",
      "301 Activation False\n",
      "302 Activation False\n",
      "303 Activation False\n",
      "304 Activation False\n",
      "305 BatchNormalization False\n",
      "306 Activation False\n",
      "307 Concatenate False\n",
      "308 Concatenate False\n",
      "309 Activation False\n",
      "310 Concatenate False\n",
      "311 Flatten True\n",
      "312 Dense True\n",
      "313 Dropout True\n",
      "314 Dense True\n"
     ]
    }
   ],
   "source": [
    "#re-check that only the last four layers are trainable\n",
    "for (i, layer) in enumerate(model.layers):\n",
    "    print(str(i)+\" \"+layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ddd626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystop =  EarlyStopping(monitor = 'val_loss',\n",
    "                          min_delta=0.005,\n",
    "                          patience=1,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True)\n",
    "\n",
    "#callbacks = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bec7750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('IncV3_checkpoint_08Mar.h5',\n",
    "                            monitor='val_accuracy',\n",
    "                            mode='max',\n",
    "                            save_best_only=True,\n",
    "                            verbose=1) #verbose = 1 to get messages during training\n",
    "\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f7e1e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def step_decay(epoch):\n",
    "    init_lr = 0.05\n",
    "    drop_lr = 0.05\n",
    "    epochs_drop = 4\n",
    "    lr = init_lr*math.pow(drop_lr, math.floor((1+epoch)/epochs_drop))\n",
    "    return lr\n",
    "\n",
    "lr_stepdecay = LearningRateScheduler(step_decay, verbose=1)\n",
    "\n",
    "callbacks = [checkpoint, lr_stepdecay]\n",
    "\n",
    "print(step_decay(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dc284a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = x_train.reshape(2000, 100, 100, 1) #60k images, 28x28 pixels and 1 to add an extra dimension\n",
    "#x_test = x_test.reshape(500, 100, 100, 1)\n",
    "\n",
    "#print(x_train[0].shape, x_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f95e3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3367 - accuracy: 0.5045\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.72800, saving model to IncV3_checkpoint_08Mar.h5\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 1.3367 - accuracy: 0.5045 - val_loss: 0.8212 - val_accuracy: 0.7280\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9394 - accuracy: 0.6470\n",
      "Epoch 00002: val_accuracy improved from 0.72800 to 0.76400, saving model to IncV3_checkpoint_08Mar.h5\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.9394 - accuracy: 0.6470 - val_loss: 0.6991 - val_accuracy: 0.7640\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8030 - accuracy: 0.6960\n",
      "Epoch 00003: val_accuracy did not improve from 0.76400\n",
      "200/200 [==============================] - 23s 114ms/step - loss: 0.8030 - accuracy: 0.6960 - val_loss: 0.6119 - val_accuracy: 0.7460\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0025000000000000005.\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5936 - accuracy: 0.7675\n",
      "Epoch 00004: val_accuracy improved from 0.76400 to 0.80400, saving model to IncV3_checkpoint_08Mar.h5\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.5936 - accuracy: 0.7675 - val_loss: 0.5385 - val_accuracy: 0.8040\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0025000000000000005.\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5596 - accuracy: 0.7900\n",
      "Epoch 00005: val_accuracy improved from 0.80400 to 0.80800, saving model to IncV3_checkpoint_08Mar.h5\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.5596 - accuracy: 0.7900 - val_loss: 0.5265 - val_accuracy: 0.8080\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0025000000000000005.\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5320 - accuracy: 0.7965\n",
      "Epoch 00006: val_accuracy improved from 0.80800 to 0.81600, saving model to IncV3_checkpoint_08Mar.h5\n",
      "200/200 [==============================] - 23s 113ms/step - loss: 0.5320 - accuracy: 0.7965 - val_loss: 0.5210 - val_accuracy: 0.8160\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0025000000000000005.\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5246 - accuracy: 0.8020\n",
      "Epoch 00007: val_accuracy did not improve from 0.81600\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.5246 - accuracy: 0.8020 - val_loss: 0.5209 - val_accuracy: 0.8140\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00012500000000000003.\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5068 - accuracy: 0.7985\n",
      "Epoch 00008: val_accuracy improved from 0.81600 to 0.82200, saving model to IncV3_checkpoint_08Mar.h5\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 0.5068 - accuracy: 0.7985 - val_loss: 0.5167 - val_accuracy: 0.8220\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00012500000000000003.\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5153 - accuracy: 0.8070\n",
      "Epoch 00009: val_accuracy improved from 0.82200 to 0.82800, saving model to IncV3_checkpoint_08Mar.h5\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.5153 - accuracy: 0.8070 - val_loss: 0.5138 - val_accuracy: 0.8280\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00012500000000000003.\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5059 - accuracy: 0.8005\n",
      "Epoch 00010: val_accuracy did not improve from 0.82800\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.5059 - accuracy: 0.8005 - val_loss: 0.5121 - val_accuracy: 0.8240\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.00012500000000000003.\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5089 - accuracy: 0.8055\n",
      "Epoch 00011: val_accuracy did not improve from 0.82800\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 0.5089 - accuracy: 0.8055 - val_loss: 0.5112 - val_accuracy: 0.8280\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 6.250000000000002e-06.\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5002 - accuracy: 0.8070\n",
      "Epoch 00012: val_accuracy did not improve from 0.82800\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 0.5002 - accuracy: 0.8070 - val_loss: 0.5111 - val_accuracy: 0.8280\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 6.250000000000002e-06.\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5011 - accuracy: 0.8065\n",
      "Epoch 00013: val_accuracy did not improve from 0.82800\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 0.5011 - accuracy: 0.8065 - val_loss: 0.5111 - val_accuracy: 0.8280\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 6.250000000000002e-06.\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.4957 - accuracy: 0.8160\n",
      "Epoch 00014: val_accuracy did not improve from 0.82800\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 0.4957 - accuracy: 0.8160 - val_loss: 0.5110 - val_accuracy: 0.8280\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 6.250000000000002e-06.\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5066 - accuracy: 0.8125\n",
      "Epoch 00015: val_accuracy did not improve from 0.82800\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 0.5066 - accuracy: 0.8125 - val_loss: 0.5110 - val_accuracy: 0.8280\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 3.125000000000001e-07.\n",
      "Epoch 16/20\n",
      " 54/200 [=======>......................] - ETA: 14s - loss: 0.4843 - accuracy: 0.8185"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21780/159032773.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m history = model.fit(x=x_train, y=y_train_cat,\n\u001b[0m\u001b[0;32m      9\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LipRead\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LipRead\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LipRead\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LipRead\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LipRead\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LipRead\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LipRead\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LipRead\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LipRead\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train the top layers of the model\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(x=x_train, y=y_train_cat,\n",
    "                    epochs=20,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(x_test,y_test_cat),\n",
    "                    batch_size=10)\n",
    "\n",
    "model.save('quickdraw10_IncV3_08Mar.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eeef5a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_test_IncV3', x_test)\n",
    "np.save('y_test_cat_IncV3', y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5778c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
